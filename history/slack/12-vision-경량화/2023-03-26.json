[
    {
        "client_msg_id": "d7f9368c-6e12-4b4e-8535-b922d724c163",
        "type": "message",
        "text": "EfficientFormer V1 &amp; V2 - 모바일 최적화된 CNN+ViT 조합\n<https:\/\/arxiv.org\/abs\/2206.01191|EfficientFormer: Vision Transformers at MobileNet Speed> (NeurIPS 2022)\n<https:\/\/arxiv.org\/abs\/2212.08059|Rethinking Vision Transformers for MobileNet Size and Speed> (ArXiv Dec 2022)\n• 핵심 아이디어: \n    ◦ 아래쪽 stage에서는 local 연산을, 위쪽 stage에서는 local + global 연산을 합니다 (Local=Conv, Global=Attention).\n    ◦ 논문 전체가 모바일 환경에 최적화하는 방법론을 다루고 있는데, 실제 측정을 기반으로 해서 논문이 탄탄합니다. 알고 있던 것들과 다른 것들이 있습니다. 예를 들어, iPhone에서는 GELU가 ReLU랑 거의 속도 차이가 없다거나, 기존 ViT patch embedding이 생각보다 많이 느리다거나 하는 등입니다.\n• 특징: \n    ◦ Self-attention 연산이 차지하는 비중이 생각보다 많지 않습니다. 주로 1\/16, 1\/32 stage에서만 수행됩니다,\n    ◦ iPhone12에서 CoreML (NPU)로 구현했을 때 *26M params, 2.7ms\/image, 83.3% accuracy*가 나옵니다. 이는 동급의 CNN, ViT 계열 모델들보다 훨씬 효율적입니다. 논문에서는 MobileNet 급이라고 서술하고 있는데 크게 틀리지 않습니다.\n    ◦ V1에서는 LayerNorm이 좀 살아 있는데, V2에서는 다 빠지면서 더 효율적이 됩니다.\n• 의견:\n    ◦ V1-&gt; V2가 많이 바뀝니다. 구조가 간단해지고 더 효율적이 되긴 하지만 V1의 디자인 철학들 중 상충되는 것들이 V2에 들어오는 게 좀 생깁니다. 그래도 뭐... 성능이 좋으니 괜찮습니다.\n    ◦ V2-L 26.1M이 제시하는 모델 중 가장 큰 모델로, ResNet-50의 25.5M에 맞춘 것 같습니다. 한 가지 함정은, ResNet-50도 iPhone 12에서 2.5ms\/img가 나옵니다. 물론 성능은 크게 향상됩니다 (78.5% -&gt; 83.5%).\n    ◦ 그래서 저는 이 논문의 의의가 이제 ViT operation을 섞어 쓰는 모델이더라도 *CNN-only 모델의 거의 완벽한 (모든 점에서) 상위호환*이 되었다는 데 있는 것 같습니다.\n    ◦ 개인적으로는, 초대형 모델들이 각광받고 있지만 아직도 이런 수요가 많이 있다고 생각합니다. 특히 모바일에서!",
        "user": "U04MQ2J38JC",
        "ts": "1679842581.845259",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "cxrhB",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "EfficientFormer V1 & V2 - 모바일 최적화된 CNN+ViT 조합\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/arxiv.org\/abs\/2206.01191",
                                "text": "EfficientFormer: Vision Transformers at MobileNet Speed"
                            },
                            {
                                "type": "text",
                                "text": " (NeurIPS 2022)\n"
                            },
                            {
                                "type": "link",
                                "url": "https:\/\/arxiv.org\/abs\/2212.08059",
                                "text": "Rethinking Vision Transformers for MobileNet Size and Speed"
                            },
                            {
                                "type": "text",
                                "text": " (ArXiv Dec 2022)\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "핵심 아이디어: "
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "아래쪽 stage에서는 local 연산을, 위쪽 stage에서는 local + global 연산을 합니다 (Local=Conv, Global=Attention)."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "논문 전체가 모바일 환경에 최적화하는 방법론을 다루고 있는데, 실제 측정을 기반으로 해서 논문이 탄탄합니다. 알고 있던 것들과 다른 것들이 있습니다. 예를 들어, iPhone에서는 GELU가 ReLU랑 거의 속도 차이가 없다거나, 기존 ViT patch embedding이 생각보다 많이 느리다거나 하는 등입니다."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 1,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "특징: "
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Self-attention 연산이 차지하는 비중이 생각보다 많지 않습니다. 주로 1\/16, 1\/32 stage에서만 수행됩니다,"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "iPhone12에서 CoreML (NPU)로 구현했을 때 "
                                    },
                                    {
                                        "type": "text",
                                        "text": "26M params, 2.7ms\/image, 83.3% accuracy",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": "가 나옵니다. 이는 동급의 CNN, ViT 계열 모델들보다 훨씬 효율적입니다. 논문에서는 MobileNet 급이라고 서술하고 있는데 크게 틀리지 않습니다."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "V1에서는 LayerNorm이 좀 살아 있는데, V2에서는 다 빠지면서 더 효율적이 됩니다."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 1,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "의견:"
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "V1-> V2가 많이 바뀝니다. 구조가 간단해지고 더 효율적이 되긴 하지만 V1의 디자인 철학들 중 상충되는 것들이 V2에 들어오는 게 좀 생깁니다. 그래도 뭐... 성능이 좋으니 괜찮습니다."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "V2-L 26.1M이 제시하는 모델 중 가장 큰 모델로, ResNet-50의 25.5M에 맞춘 것 같습니다. 한 가지 함정은, ResNet-50도 iPhone 12에서 2.5ms\/img가 나옵니다. 물론 성능은 크게 향상됩니다 (78.5% -> 83.5%)."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "그래서 저는 이 논문의 의의가 이제 ViT operation을 섞어 쓰는 모델이더라도 "
                                    },
                                    {
                                        "type": "text",
                                        "text": "CNN-only 모델의 거의 완벽한 (모든 점에서) 상위호환",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": "이 되었다는 데 있는 것 같습니다."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "개인적으로는, 초대형 모델들이 각광받고 있지만 아직도 이런 수요가 많이 있다고 생각합니다. 특히 모바일에서!"
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 1,
                        "border": 0
                    }
                ]
            }
        ],
        "team": "T04MCQMEXQ9",
        "user_team": "T04MCQMEXQ9",
        "source_team": "T04MCQMEXQ9",
        "user_profile": {
            "avatar_hash": "3e494054f705",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-01-28\/4714393981186_3e494054f7050068883f_72.png",
            "first_name": "심규홍\/퀄컴",
            "real_name": "심규홍\/퀄컴",
            "display_name": "",
            "team": "T04MCQMEXQ9",
            "name": "khshim20",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679842581.845259",
        "reply_count": 5,
        "reply_users_count": 4,
        "latest_reply": "1679912449.136549",
        "reply_users": [
            "U04M05UHX7U",
            "U04LKU43D7Z",
            "U04LL3W56F9",
            "U04MQ2J38JC"
        ],
        "replies": [
            {
                "user": "U04M05UHX7U",
                "ts": "1679875084.968969"
            },
            {
                "user": "U04M05UHX7U",
                "ts": "1679875175.124969"
            },
            {
                "user": "U04LKU43D7Z",
                "ts": "1679879800.836569"
            },
            {
                "user": "U04LL3W56F9",
                "ts": "1679909843.224329"
            },
            {
                "user": "U04MQ2J38JC",
                "ts": "1679912449.136549"
            }
        ],
        "is_locked": false,
        "subscribed": true,
        "last_read": "1679912449.136549",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U04M2NY6U2Y",
                    "U04LKU43D7Z",
                    "U04LTPY7LES",
                    "U04LTMVAQ4W",
                    "U04M091M3MZ",
                    "U04QJNZDDFB",
                    "U04LV2JHHB8",
                    "U04MCA1D8G5",
                    "U04MD0GTCG1",
                    "U04LXKFJLFP",
                    "U04M3UUAZTN"
                ],
                "count": 11
            }
        ]
    },
    {
        "client_msg_id": "d2686536-d79c-43be-a9e1-f1665503e665",
        "type": "message",
        "text": "ViT 이후 비전 최적화 논문은 끝이 없군요.. ㅎㅎ.. 가장 최근에 본게 ConvNeXT랑 Next-ViT인데.. follow-up이 안됩니다.. ㅋㅋ..",
        "user": "U04M05UHX7U",
        "ts": "1679875084.968969",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uVp",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "ViT 이후 비전 최적화 논문은 끝이 없군요.. ㅎㅎ.. 가장 최근에 본게 ConvNeXT랑 Next-ViT인데.. follow-up이 안됩니다.. ㅋㅋ.."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T04MCQMEXQ9",
        "user_team": "T04MCQMEXQ9",
        "source_team": "T04MCQMEXQ9",
        "user_profile": {
            "avatar_hash": "8160001f5214",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-01-29\/4699744492023_8160001f52148d13414d_72.jpg",
            "first_name": "권세중\/네이버클라우드",
            "real_name": "권세중\/네이버클라우드",
            "display_name": "권세중\/네이버클라우드",
            "team": "T04MCQMEXQ9",
            "name": "sejung.kwon",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679842581.845259",
        "parent_user_id": "U04MQ2J38JC",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U04LKU43D7Z"
                ],
                "count": 1
            },
            {
                "name": "smiling_face_with_tear",
                "users": [
                    "U04MQ2J38JC"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "e28d3fd8-7abb-4a7c-953a-33408008f857",
        "type": "message",
        "text": "저는 주로 LLM을 하고 있습니다만, 마지막줄에 동의합니다. ㅎㅎ 다만, 열심히 최적화하는만큼 돈이 되는 서비스냐 하는 문제가..",
        "user": "U04M05UHX7U",
        "ts": "1679875175.124969",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tUzIX",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "저는 주로 LLM을 하고 있습니다만, 마지막줄에 동의합니다. ㅎㅎ 다만, 열심히 최적화하는만큼 돈이 되는 서비스냐 하는 문제가.."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T04MCQMEXQ9",
        "user_team": "T04MCQMEXQ9",
        "source_team": "T04MCQMEXQ9",
        "user_profile": {
            "avatar_hash": "8160001f5214",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-01-29\/4699744492023_8160001f52148d13414d_72.jpg",
            "first_name": "권세중\/네이버클라우드",
            "real_name": "권세중\/네이버클라우드",
            "display_name": "권세중\/네이버클라우드",
            "team": "T04MCQMEXQ9",
            "name": "sejung.kwon",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679842581.845259",
        "parent_user_id": "U04MQ2J38JC",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U04LKU43D7Z",
                    "U04MQ2J38JC"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "323014dd-0d62-45f2-ae37-eee5dee8e177",
        "type": "message",
        "text": "Hybrid VIT에 관심이 있어서 해당 모델도 보고 있었는데 정리 감사합니다.",
        "user": "U04LKU43D7Z",
        "ts": "1679879800.836569",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "4+bC8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Hybrid VIT에 관심이 있어서 해당 모델도 보고 있었는데 정리 감사합니다."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T04MCQMEXQ9",
        "user_team": "T04MCQMEXQ9",
        "source_team": "T04MCQMEXQ9",
        "user_profile": {
            "avatar_hash": "bba3114c98fa",
            "image_72": "https:\/\/avatars.slack-edge.com\/2023-01-29\/4707892166534_bba3114c98fa5a613cdf_72.png",
            "first_name": "이제민\/ETRI",
            "real_name": "이제민\/ETRI",
            "display_name": "",
            "team": "T04MCQMEXQ9",
            "name": "leejaymin",
            "is_restricted": false,
            "is_ultra_restricted": false
        },
        "thread_ts": "1679842581.845259",
        "parent_user_id": "U04MQ2J38JC",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U04M05UHX7U",
                    "U04MQ2J38JC"
                ],
                "count": 2
            }
        ]
    }
]